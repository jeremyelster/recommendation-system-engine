{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System Notebook Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. [Params](#Params)\n",
    "1. [Acquisitor and Cleaner](#Acquisitor-and-Cleaner)\n",
    "2. [Training Preparator](#Training-Preparator)\n",
    "3. [Trainer](#Trainer)\n",
    "4. [Metrics Evaluator](#Metrics-Evaluator)\n",
    "5. [Prediction Preparator](#Prediction-Preparator)\n",
    "6. [Predictor](#Predictor)\n",
    "7. [Feedback](#Feedback)\n",
    "8. [Sample Application](#Sample-Application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin_recommendation_system_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "params = {\n",
    "    \"param_grid\": {\n",
    "        'n_epochs': [5, 10], \n",
    "        'lr_all': [0.002, 0.005],\n",
    "        'reg_all': [0.4, 0.6]  \n",
    "    },\n",
    "    \"algo\": SVD,\n",
    "    \"measures\": ['rmse', 'mae'],\n",
    "    \"n_cv\": 3,\n",
    "    \n",
    "    \"prediction\": {\n",
    "        \"pred_type\": \"top_n\",\n",
    "        \"n_pred\": 10\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"param_grid\": {\n",
    "        \"k\": [20, 30, 40]\n",
    "    },\n",
    "    \"sim_options\": {\n",
    "        'name': 'pearson_baseline',\n",
    "        'user_based': False  # compute  similarities between items\n",
    "    },\n",
    "    \"algo\": KNNBaseline,\n",
    "    \"measures\": ['rmse', 'mae'],\n",
    "    \"n_cv\": 3,\n",
    "    \n",
    "    \"prediction\": {\n",
    "        \"pred_type\": \"all\",\n",
    "        \"n_pred\": 10\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquisitor and Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "marvin_cell": "acquisitor"
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "marvin_initial_dataset = {\n",
    "    \"data\": data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Preparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "marvin_cell": "tpreparator"
   },
   "outputs": [],
   "source": [
    "trainset = marvin_initial_dataset[\"data\"].build_full_trainset()\n",
    "testset = trainset.build_anti_testset()\n",
    "\n",
    "marvin_dataset = {\n",
    "    \"data\": marvin_initial_dataset[\"data\"],\n",
    "    \"trainset\": trainset,\n",
    "    \"testset\": testset\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    params[\"algo\"],\n",
    "    params[\"param_grid\"],\n",
    "    measures=params[\"measures\"],\n",
    "    cv=params[\"n_cv\"])\n",
    "\n",
    "gs.fit(marvin_dataset[\"data\"])\n",
    "\n",
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator['rmse']\n",
    "algo.fit(marvin_dataset[\"trainset\"])\n",
    "\n",
    "\n",
    "# Get the predictions for null values in the set\n",
    "if params[\"prediction\"][\"pred_type\"] == \"top_n\":\n",
    "    predictions = algo.test(marvin_dataset[\"testset\"])\n",
    "else:\n",
    "    predictions = \"To generate predictions, set prediction pred_type to top_n\"\n",
    "\n",
    "marvin_model = {\n",
    "    \"grid_search\": gs,\n",
    "    \"model\": algo,\n",
    "    \"predictions\": predictions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "marvin_cell": "trainer"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "algo = params[\"algo\"](sim_options=params[\"sim_options\"])\n",
    "algo.fit(marvin_dataset[\"trainset\"])\n",
    "\n",
    "\n",
    "# Get the predictions for null values in the set\n",
    "if params[\"prediction\"][\"pred_type\"] == \"top_n\":\n",
    "    predictions = algo.test(marvin_dataset[\"testset\"])\n",
    "else:\n",
    "    predictions = \"To generate predictions, set prediction pred_type to top_n\"\n",
    "\n",
    "marvin_model = {\n",
    "    #\"grid_search\": gs,\n",
    "    \"model\": algo,\n",
    "    \"predictions\": predictions\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "marvin_cell": "evaluator"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'grid_search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-8c25f5af9452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarvin_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grid_search\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# combination of parameters that gave the best RMSE score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Model: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarvin_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grid_search\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'grid_search'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame.from_dict(marvin_model[\"grid_search\"].cv_results)\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(\"Best Model: {}\".format([key + \": \" + str(value) for (key,value) in marvin_model[\"grid_search\"].best_params['rmse'].items()]))\n",
    "\n",
    "# best RMSE score\n",
    "print(\"Best RMSE: {}\".format(marvin_model[\"grid_search\"].best_score['rmse']))\n",
    "\n",
    "\n",
    "df_results[['params', 'mean_test_mae', 'mean_test_rmse', 'mean_test_time']].sort_values('mean_test_rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Preparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = {\n",
    "    \"User_id\": 196,\n",
    "    \"Item_id\": 302\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import get_dataset_dir\n",
    "import io\n",
    "def read_item_names():\n",
    "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
    "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid\n",
    "\n",
    "def get_top_n_for_user(predictions, userId, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        userId(str): Target User Id \n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "    # First map the predictions to each user.\n",
    "    user_predictions = [(iid, est) for (uid, iid, true_r, est, _) in predictions if uid == str(userId)]\n",
    "    # Read the mappings raw id <-> movie name\n",
    "    rid_to_name, name_to_rid = read_item_names()\n",
    "    \n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    user_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n = [(rid_to_name[pid], val)  for (pid, val) in user_predictions[:n]]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_top_neighbors(model, targetId, kind=\"Item\", n=10):\n",
    "    # Read the mappings raw id <-> movie name\n",
    "    rid_to_name, name_to_rid = read_item_names()\n",
    "    \n",
    "    if kind==\"Item\":\n",
    "        # Retrieve inner id of the movie Toy Story\n",
    "        item_raw_id = name_to_rid['Toy Story (1995)']\n",
    "        print(item_raw_id)\n",
    "        item_inner_id = model[\"model\"].trainset.to_inner_iid(item_raw_id)\n",
    "        print(item_inner_id)\n",
    "        # Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "        item_neighbors = model[\"model\"].get_neighbors(item_inner_id, k=n)\n",
    "\n",
    "        # Convert inner ids of the neighbors into names.\n",
    "        item_neighbors = (model[\"model\"].trainset.to_raw_iid(inner_id)\n",
    "                               for inner_id in item_neighbors)\n",
    "        item_neighbors = (rid_to_name[rid]\n",
    "                               for rid in item_neighbors)\n",
    "\n",
    "        print()\n",
    "        print('The 10 nearest neighbors of Toy Story are:')\n",
    "        for movie in item_neighbors:\n",
    "            print(movie)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "24\n",
      "()\n",
      "The 10 nearest neighbors of Toy Story are:\n",
      "Beauty and the Beast (1991)\n",
      "Raiders of the Lost Ark (1981)\n",
      "That Thing You Do! (1996)\n",
      "Lion King, The (1994)\n",
      "Craft, The (1996)\n",
      "Liar Liar (1997)\n",
      "Aladdin (1992)\n",
      "Cool Hand Luke (1967)\n",
      "Winnie the Pooh and the Blustery Day (1968)\n",
      "Indiana Jones and the Last Crusade (1989)\n"
     ]
    }
   ],
   "source": [
    "pred = get_top_neighbors(marvin_model, 1, kind=\"Item\", n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.16   {u'actual_k': 39, u'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# get a prediction for specific users and items.\n",
    "pred = marvin_model[\"model\"].predict(\n",
    "    str(input_message[\"User_id\"]), str(input_message[\"Item_id\"]), r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-ec73d2637caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m pred = get_top_n_for_user(\n\u001b[0;32m----> 2\u001b[0;31m     marvin_model[\"predictions\"], userId=input_message[\"User_id\"], n=params[\"prediction\"][\"n_pred\"])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-162-7969e67c4118>\u001b[0m in \u001b[0;36mget_top_n_for_user\u001b[0;34m(predictions, userId, n)\u001b[0m\n\u001b[1;32m     32\u001b[0m     '''\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# First map the predictions to each user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0muser_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Read the mappings raw id <-> movie name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mrid_to_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_to_rid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_item_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "pred = get_top_n_for_user(\n",
    "    marvin_model[\"predictions\"], userId=input_message[\"User_id\"], n=params[\"prediction\"][\"n_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1\n",
      "2: 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-048cf12de13e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0}: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "for i, res in enumerate(pred):\n",
    "    print(\"{0}: {1}\".format(i+1,res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "24\n",
      "()\n",
      "The 10 nearest neighbors of Toy Story are:\n",
      "So Dear to My Heart (1949)\n",
      "My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)\n",
      "Somebody to Love (1994)\n",
      "Crows and Sparrows (1949)\n",
      "Total Eclipse (1995)\n",
      "Mr. Jones (1993)\n",
      "Convent, The (Convento, O) (1995)\n",
      "Incognito (1997)\n",
      "Every Other Weekend (1990)\n",
      "Homage (1995)\n"
     ]
    }
   ],
   "source": [
    "pred = get_top_neighbors(marvin_dataset, marvin_model, 1, kind=\"Item\", n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <surprise.prediction_algorithms.knns.KNNBaseline at 0x7f71b2010250>,\n",
       " 'predictions': 'To generate predictions, set prediction pred_type to top_n'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marvin_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "()\n",
      "The 10 nearest neighbors of Toy Story are:\n",
      "(u'588', u'Beauty and the Beast (1991)')\n",
      "(u'174', u'Raiders of the Lost Ark (1981)')\n",
      "(u'845', u'That Thing You Do! (1996)')\n",
      "(u'71', u'Lion King, The (1994)')\n",
      "(u'928', u'Craft, The (1996)')\n",
      "(u'294', u'Liar Liar (1997)')\n",
      "(u'95', u'Aladdin (1992)')\n",
      "(u'523', u'Cool Hand Luke (1967)')\n",
      "(u'969', u'Winnie the Pooh and the Blustery Day (1968)')\n",
      "(u'210', u'Indiana Jones and the Last Crusade (1989)')\n",
      "RMSE: 0.4807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48071109787164656"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise import KNNBaseline\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Retrieve inner id of the movie Toy Story\n",
    "toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
    "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n",
    "\n",
    "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in toy_story_neighbors)\n",
    "toy_story_neighbors = ((rid, rid_to_name[rid])\n",
    "                       for rid in toy_story_neighbors)\n",
    "print()\n",
    "print('The 10 nearest neighbors of Toy Story are:')\n",
    "for movie in toy_story_neighbors:\n",
    "    print(movie)\n",
    "    \n",
    "testset = trainset.build_testset()\n",
    "predictions = algo.test(testset)\n",
    "# RMSE should be low as we are biased\n",
    "accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "()\n",
      "The 10 nearest neighbors of Toy Story are:\n",
      "(u'626', u'So Dear to My Heart (1949)')\n",
      "(u'1332', u\"My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)\")\n",
      "(u'1334', u'Somebody to Love (1994)')\n",
      "(u'1350', u'Crows and Sparrows (1949)')\n",
      "(u'1260', u'Total Eclipse (1995)')\n",
      "(u'1436', u'Mr. Jones (1993)')\n",
      "(u'1342', u'Convent, The (Convento, O) (1995)')\n",
      "(u'361', u'Incognito (1997)')\n",
      "(u'1348', u'Every Other Weekend (1990)')\n",
      "(u'1320', u'Homage (1995)')\n",
      "RMSE: 0.7833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78332978015773791"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise import KNNBaseline\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Retrieve inner id of the movie Toy Story\n",
    "toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
    "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n",
    "\n",
    "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in toy_story_neighbors)\n",
    "toy_story_neighbors = ((rid, rid_to_name[rid])\n",
    "                       for rid in toy_story_neighbors)\n",
    "print()\n",
    "print('The 10 nearest neighbors of Toy Story are:')\n",
    "for movie in toy_story_neighbors:\n",
    "    print(movie)\n",
    "    \n",
    "testset = trainset.build_testset()\n",
    "predictions = algo.test(testset)\n",
    "# RMSE should be low as we are biased\n",
    "accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67472604548514004"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise import KNNBaseline\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "#sim_options = {'name': 'cosine', 'user_based': False}\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "\n",
    "    \n",
    "testset = trainset.build_testset()\n",
    "predictions = algo.test(testset)\n",
    "# RMSE should be low as we are biased\n",
    "accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
